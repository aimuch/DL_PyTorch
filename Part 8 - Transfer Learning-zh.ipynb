{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 迁移学习\n",
    "\n",
    "在这个 notebook 中，你将学习如何使用预先训练的神经网络解决计算机视觉领域的挑战。具体来说，你使用的网络根据 [ImageNet](http://www.image-net.org/) 中的图像进行训练，你可以在 [torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html) 中找到这些模型。\n",
    "\n",
    "ImageNet 是一个庞大的数据集，其中有超过一百万张带有标签的图像，来自一千个不同类别。通常，我们使用一种名为卷积层的结构训练深度神经网络。在这里，我并不会深入介绍卷积网络，但如果你感兴趣，可以查看[这个视频](https://www.youtube.com/watch?v=2-Ol7ZB0MmU)。\n",
    "\n",
    "一旦经过训练，这些模型便能以绝佳表现检测未见过的图像的特征。这种使用预先训练的网络来分析训练集之外的图像的方法被称为迁移学习。在这里，我们将使用迁移学习来训练一个能够以近乎完美的准确性分类猫狗图像的网络。\n",
    "\n",
    "使用 `torchvision.models`，你可以下载这些预先训练的网络，并用于你的应用中。我们现在将导入 `models`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数预先训练的模型要求输入为 224x224 像素的图像。同样地，我们需要匹配训练模型时进行的标准化。每个颜色通道都分别进行了标准化，均值为 `[0.485, 0.456, 0.406]`，标准差为 `[0.229, 0.224, 0.225]`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以载入一个模型，比如 [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5)。现在让我们打印出这个模型的结构，以便了解细节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.1): ReLU(inplace)\n",
       "        (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "        (relu.2): ReLU(inplace)\n",
       "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型主要有两个部分，即特征和分类器。特征部分是一堆卷积层，能作为特征检测器输入分类器中。分类器部分是一个单独的全连接层 `(classifier): Linear(in_features=1024, out_features=1000)`。这个层根据 ImageNet 数据集训练，因此无法解决我们指定的问题。这意味着我们需要替换这个分类器，不过这些特征本身能起到很大的作用。一般来说，我认为预先训练的网络是绝佳的特征检测器，可以作为简单的前馈分类器的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在构建好模型之后，我们需要训练分类器。然而，现在我们使用的是一个**非常深**的神经网络。如果你还像之前一样试图在 CPU 上训练它，这会耗费相当长的时间。因此，我们将使用 GPU 来进行运算。在 GPU 上，线性代数运算同步进行，这使得运算速度提升了 100x。我们还可以在多个 GPU 上进行训练，这能进一步缩短训练时间。\n",
    "\n",
    "PyTorch 和其他深度学习框架一样，使用 [CUDA](https://developer.nvidia.com/cuda-zone) 来高效地在 GPU 上计算前向和后向传播。在 PyTorch 中，你可以使用 `model.cuda()` 将模型参数和其他张量转移到 GPU 内存中。当你需要在 PyTorch 之外处理网络的输出时，你也可以使用 `model.cpu()` 再将它们从 GPU 上转移回去。我将分别使用 GPU 和不使用 GPU 进行前向传播和后向传播，好为你展示着两者之间计算速度的差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA = False; Time per batch: 9.257 seconds\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3e42bd46f666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Move model parameters to the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# Variables stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0;31m# We need this method only for lazy init, so we can remove it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0m_CudaBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m         raise RuntimeError(\n\u001b[1;32m    140\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_sparse_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "for cuda in [False, True]:\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    # Only train the classifier parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "    if cuda:\n",
    "        # Move model parameters to the GPU\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model.cpu()\n",
    "\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        if cuda:\n",
    "            # Move input and label tensors to the GPU\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if ii==3:\n",
    "            break\n",
    "        \n",
    "    print(f\"CUDA = {cuda}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = False; Time per batch: 5.443 seconds\n",
    "CUDA = True; Time per batch: 0.009 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了手动设置 `cuda` 外，你还可以通过 `cuda = torch.cuda.is_available()` 查看 CUDA 是否可用。\n",
    "\n",
    "从这里开始，你将自己完成这个模型的训练。这个过程和之前一样，不过现在你的模型更加强大。你的准确率可以轻易达到 95% 以上。\n",
    "\n",
    ">**练习：** 训练一个预先训练的模型来给猫狗图像分类。你可以在 DenseNet 模型的基础上训练，也可以尝试 ResNet，这也是一个非常优秀的模型。请确保你只训练了分类器，而特征参数部分保留不动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a model with a pre-trained network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
